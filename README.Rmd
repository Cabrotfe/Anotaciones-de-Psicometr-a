---
title: "Análisis Psicométricos"
output: github_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse, mirt, corrplot,assertr,sjPlot, lavaan)
```

## Simulación de datos

Vamos a hacer análisis de ítems de una prueba que suponemos mide una sola dimensión. Esto es, que hay solo un atributo psicológico que genera el patrón de respuestas observado (o que induce la covariación entre ítems).

Vamos a generar ítems de fácil, media y alta dificultad.

```{r}
betas = matrix(c(1,1.3,1.8,2,2.1, # ítems fáciles
          0,0.3,0.5,-0.5,-0.8,  #  ítems medios
          -1,-1.2,-1.5,-1.7,-1.4), ncol = 1) ## ítems difíciles

alfas = matrix(c(1.2,1.2,1.3,1.4,1.1, 
          0.8,0.9,1.1,1.3,1.5,
          0.7,0.6,0.9,1.2,1.5),ncol=1)

guess = matrix(c(0.1,0.1,0.1,0.1,0.1,
          0.15,0.15,0.15,0.15,0.15,
          0.2,0.2,0.2,0.2,0.2),ncol=1)

theta = matrix(rnorm(400, 0.5, 1),ncol=1)
```



```{r}
base_datos=simdata(a=alfas,d=betas, guess = guess,itemtype = "3PL", Theta = theta)
base_datos = data.frame(base_datos)
head(base_datos)
```



# Descriptivos

Algunos datos que nos pueden interesar son los descriptivos, correlaciones ítem test y consistencia interna. Para ello, podríamos ocupar la siguiente función:

```{r}
sjPlot::sjt.itemanalysis(base_datos)
```


Algo que es útil es ordenar los ítems por dificultad. Para ello, podríamos ocupar el siguiente código:


```{r}
a=base_datos %>% summarise(across(.cols=everything(), mean,na.rm=T)) %>% t()
a=sort(a[,1], decreasing = T)
base_datos_sort=base_datos[,c(names(a))]
head(base_datos)
```


Podríamos crear una función para ordenar ítems:

```{r}
orden_items=function(items){
 it_prop=items %>% summarise(across(.cols=everything(), mean,na.rm=T)) %>% t()
 it_prop=sort(it_prop[,1], decreasing = T)
 items=items[,c(names(it_prop))]
 return(items)
}
```

# Covarianzas:

También nos pueden interesar las covarianzas. Ello da una idea de la estructura interna del instrumento. 

```{r}
corrplot(cor(base_datos), method = "ellipse", order="hclust",addrect=2)
```



```{r}
sjPlot::sjp.corr(base_datos, decimals = 2)
```



# Teoría clásica de tests

Lo más importante es la confiabilidad. Esto es la correlación al cuadrado del puntaje observado con el puntaje verdadero. El puntaje verdadero no es estimable porque es la esperanza matemática de aplicaciones suscesivas e idénticas de un test. Decimos que toda cosa tiene teóricamente un puntaje verdadero E(X), pero no podemos establecerlo.
Podemos entonces estimar la correlación entre X y T?
La respuesta es: sí y no. Se requiere asumir supuestos, en particular de test paralelos, o de tau equivalencia.

Test paralelos nos permite asumir que la correlación entre dos test es igual a la confiabilidad.
Tau-equivalencia nos permite asumir que la covarianza entre 2 test es igual a varianza verdadera, sin embargo, la correlación entre tests tau-equivalentes no permite asumir confiabilidad, pues las varianzas X1 y X2 no son necesariamente iguales. La Tau-equivalencia señala que dos o más test tienen la misma cantidad de varianza verdadera pero, esta varianza verdadera puede significar una distinta proporción del test de modo que los tests tienen distinta confiabilidad.  



### Modelo de test paralelos:

Podemos ocupar un modelo de variables latentes que de cuenta de los supuestos de test paralelos. Con test paralelos asumimos que los ítems comparten la misma cantidad y proporción de varianza verdadera (igual confiabilidad). Con los índices de ajuste, podemos determinar si el supuesto de test paralelos es razonable o no.


```{r}
str_c(colnames(base_datos),"~~e*",colnames(base_datos), collapse = ";")
cfa_ctt_paralel = "f1=~b*Item_1+b*Item_2+b*Item_3+b*Item_4+b*Item_5+b*Item_6+b*Item_7+b*Item_8+b*Item_9+b*Item_10+b*Item_11+b*Item_12+b*Item_13+b*Item_14+b*Item_15
Item_1~~e*Item_1;Item_2~~e*Item_2;Item_3~~e*Item_3;
Item_4~~e*Item_4;Item_5~~e*Item_5;Item_6~~e*Item_6;
Item_7~~e*Item_7;Item_8~~e*Item_8;Item_9~~e*Item_9;
Item_10~~e*Item_10;Item_11~~e*Item_11;Item_12~~e*Item_12;
Item_13~~e*Item_13;Item_14~~e*Item_14;Item_15~~e*Item_15"
cfa_ctt_model_paralel = sem(model = cfa_ctt_paralel, estimator = "MLR", data = base_datos)
lavaan::fitted(cfa_ctt_model_paralel)
```

la pregunta es, ¿es esta matriz similar a la matriz original?
Podemos asumir que en la población, esta es la matriz que real, ¿en cuánto difiere esa matriz con esta?

Los residuos indican la discrepancia:

```{r}
residuals(cfa_ctt_model_paralel)
```


Podemos atender a otra cosa, en este modelo los valores del factor son lineales con los puntajes observados. Es posible estimar, desde los puntajes observados, el puntaje del factor.

```{r}
plot(lavPredict(cfa_ctt_model_paralel, method = "Bartlett"), rowSums(base_datos))
```


# Modelo de tau-equivalencia

Este es el modelo asumido en el cálculo del alpha de cronbach. El alpha hace una descomposición de varianza verdadera y varianza total, asumiendo que la varianza verdadera es igual al promedio de la covarianza observada, multiplicada por el total de elementos de la matriz varianza covarianza. Esto es, que la matriz tiene k^2 elementos var(T).

```{r}
tot_covar=sum(var(base_datos)) - sum(diag(var(base_datos))) ## Suma de todas las covarianzas
tot_covar/(15*14) ## esta es la covarianza promedio. Sería T. Se asume, que hay 15^2 Ts en la matriz
tot_covar*15^2/((15*14)*sum(var(base_datos))) ## así, tenemos el total es Ts de la matriz, dividido por la varianza total. Esto es el alpha
```


La diagnonal de la matriz tiene varianza verdadera y varianza error. Lo que está fuera de la diagonal es varianza verdadera (covarianzas)

¿Deberíamos asumir que la covarianza entre ítems es igual a la varianza verdadera?


```{r}
cfa_ctt_tau = "f1=~b*Item_1+b*Item_2+b*Item_3+b*Item_4+b*Item_5+b*Item_6+b*Item_7+b*Item_8+b*Item_9+b*Item_10+b*Item_11+b*Item_12+b*Item_13+b*Item_14+b*Item_15"
cfa_ctt_model_tau = sem(model = cfa_ctt_tau, estimator = "MLR", data = base_datos)
lavaan::fitted(cfa_ctt_model_tau) ## la pregunta es, ¿es esta matriz similar a la matriz original?
```

Podemos asumir que en la población, esta es la matriz que real, ¿en cuánto difiere esa matriz con esta?

```{r}
residuals(cfa_ctt_model_tau)
```


Respecto a los puntajes observados, acá comienza a versa la indeterminancia de los puntajes del factor, por el hecho de que los ítems entregan distinta cantidad de información para predecir los puntajes del factor. 

```{r}
plot(lavPredict(cfa_ctt_model_tau, method = "Bartlett"), rowSums(base_datos))
```


# Modelo congenérico 

En este caso, dado que los ítems tienen distinto grado de covarianza entre sí, y que hay ítems que tienen muy poca covarianza con los demás ítems, decimos que no todos los ítems se relacionan con igual magnitud con el factor. Hay ítems que se relacionan fuertemente con el factor (la covarianza en general reperesenta una alta proporción de la varianza del ítem) e ítems con baja asociación con el factor. 

```{r}
congeneric = "f1=~Item_1+Item_2+Item_3+Item_4+Item_5+Item_6+Item_7+Item_8+Item_9+Item_10+Item_11+Item_12+Item_13+Item_14+Item_15"
congeneric_model = sem(model=congeneric, data=base_datos, estimator="MLR")
fitted(congeneric_model)
```

la discrepancia entre la matriz reproducida por el modelo y la matriz original es la siguiente:
```{r}
residuals(congeneric_model)
```

Respecto a los puntajes observados, acá comienza a versa la indeterminancia de los puntajes del factor, por el hecho de que los ítems entregan distinta cantidad de información para predecir los puntajes del factor. 

```{r}
plot(lavPredict(congeneric_model, method = "regression"), rowSums(base_datos))
```




